p <- fun(Glass=Glass, i=i)
pp <- c(pp, list(p))
}
do.call("grid.arrange", c(pp, ncol=ncol))
}
plotDen <- function(Glass, i){
data <- data.frame(x=Glass[[i]], type = Glass$Type)
df <- as.data.frame(mean(data$x))
colnames(df) <- "mean"
df$median <- median(data$x)
p <- ggplot(data= data) +
geom_line(aes(x = x), stat = 'density', size = 1,alpha = 1.0) +
xlab(paste0((colnames(Glass)[i]), '\n',
'Skewness: ',round(skewness(Glass[[i]], na.rm = TRUE), 4), '\n',
'Mean: ', round(df$mean, 4), '\n',
'Median: ', round(df$median, 4))) +
theme_light() +
geom_vline(data=df, aes(xintercept=df$mean), linetype = "dashed", size=1, colour="red") +
geom_vline(data=df, aes(xintercept=df$median), size = 1, colour="blue")
return(p)
}
doPlots(Glass, plotDen, ii=1:9, ncol=2)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE,
message=FALSE,
collapse = FALSE,
comment = "#>" )
library(ggfortify)
library(openxlsx)
library(fpp2)
library(fma)
library(gridExtra)
library(seasonal)
library(ggplot2)
library(patchwork)
library(caret)
library(grid)
#help function for each series using question mark "??"
??gold
#help function for each series using question mark "??"
??woolyrnq
#help function for each series using question mark "??"
??gas
#autoplots of each series
grid.arrange(autoplot(gold),autoplot(woolyrnq),autoplot(gas))
#frequency of each series
frequency(gold)
frequency(woolyrnq)
frequency(gas)
#calling which.max() function
which.max(gold)
#printing maximum value
gold[which.max(gold)]
retaildata <- read.xlsx("https://otexts.com/fpp2/extrafiles/retail.xlsx",startRow = 2)
myts <- ts(retaildata[,"A3349873A"],
frequency=12, start=c(1982,4))
#myts  #code is silent because it represents an example - see "myts2"
myts2 <- ts(retaildata[,"A3349791W"],
frequency=12, start=c(1982,4))
#time series qutoplot
autoplot(myts2)
#time series seasonal plot
ggseasonplot(myts2)
#time series sub series plot
ggsubseriesplot(myts2)
#autoplot(), ggseasonplot(), ggsubseriesplot(), gglagplot(), ggAcf()
p1 <- autoplot(plastics)
p2 <- ggseasonplot(plastics)
p3 <- ggsubseriesplot(plastics)
p4 <- gglagplot(plastics)
p5 <- ggAcf(plastics)
p1 / p2 / p3 / p5
p4
#multiplicative decomposition
decomp_plastics <- plastics %>%
decompose(type = "multiplicative")
decomp_plastics %>% autoplot()
autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted")
plasticsOutlier <- plasticsplasticsOutlier[30] <- plasticsOutlier[30] + 500autoplot(plasticsOutlier, series = "Data") +  autolayer(trendcycle(fit), series = "Trend") +  autolayer(seasadj(fit), series = "Seasonally Adjusted") +   xlab("Year") + ylab("Monthly Sales (in thousands)") +  ggtitle("Seasonally Adjusted Plastics Manufacturer Sales Data") +  scale_color_manual(values = c("blue", "green", "red"),                     breaks = c("Data", "Trend", "Seasonally Adjusted"))
plasticsOutlier <- plastics
knitr::opts_chunk$set(echo=TRUE, warning=FALSE,
message=FALSE,
collapse = FALSE,
comment = "#>" )
library(ggfortify)
library(openxlsx)
library(fpp2)
library(fma)
library(gridExtra)
library(seasonal)
library(ggplot2)
library(patchwork)
library(caret)
library(grid)
#help function for each series using question mark "??"
??gold
#help function for each series using question mark "??"
??woolyrnq
#help function for each series using question mark "??"
??gas
#autoplots of each series
grid.arrange(autoplot(gold),autoplot(woolyrnq),autoplot(gas))
#frequency of each series
frequency(gold)
frequency(woolyrnq)
frequency(gas)
#calling which.max() function
which.max(gold)
#printing maximum value
gold[which.max(gold)]
retaildata <- read.xlsx("https://otexts.com/fpp2/extrafiles/retail.xlsx",startRow = 2)
myts <- ts(retaildata[,"A3349873A"],
frequency=12, start=c(1982,4))
#myts  #code is silent because it represents an example - see "myts2"
myts2 <- ts(retaildata[,"A3349791W"],
frequency=12, start=c(1982,4))
#time series qutoplot
autoplot(myts2)
#time series seasonal plot
ggseasonplot(myts2)
#time series sub series plot
ggsubseriesplot(myts2)
#autoplot(), ggseasonplot(), ggsubseriesplot(), gglagplot(), ggAcf()
p1 <- autoplot(plastics)
p2 <- ggseasonplot(plastics)
p3 <- ggsubseriesplot(plastics)
p4 <- gglagplot(plastics)
p5 <- ggAcf(plastics)
p1 / p2 / p3 / p5
p4
#multiplicative decomposition
decomp_plastics <- plastics %>%
decompose(type = "multiplicative")
decomp_plastics %>% autoplot()
autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted")
plastics %>% decompose(type = "multiplicative") -> fit
autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted")
plastics %>% decompose(type = "multiplicative") -> fit
autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted")
plastics %>% decompose(type = "multiplicative") -> fit
autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted")
plastics_mid <- plastics
plastics_end <- plastics
plastics_mid[30] <- plastics_mid[30] + 500 #outlier in the middle
plastics_end[52] <- plastics_end[52] + 500 #outlier to reflect "near the end"
decomp_mid <- plastics_mid %>%
decompose(type = "multiplicative")
p <- autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted") +
ggtitle("Plastics Seasonally Adjusted - Original") +
theme(plot.title = element_text(size = 14))
p1 <- autoplot(plastics_mid, series = "Data") +
autolayer(trendcycle(decomp_mid), series = "Trend") +
autolayer(seasadj(decomp_mid), series = "Seasonally Adjusted") +
ggtitle("Plastics Seasonally Adjusted - Mid Observation")+
theme(plot.title = element_text(size = 14))
decomp_end <- plastics_end %>%
decompose(type = "multiplicative")
p2 <- autoplot(plastics_end, series = "Data") +
autolayer(trendcycle(decomp_end), series = "Trend") +
autolayer(seasadj(decomp_end), series = "Seasonally Adjusted") +
ggtitle("Plastics Seasonally Adjusted - Near the End Observation")+
theme(plot.title = element_text(size = 14))
grid.arrange(p, p1,p2)
plastics_mid <- plastics
plastics_end <- plastics
plastics_mid[30] <- plastics_mid[30] + 500 #outlier in the middle
plastics_end[52] <- plastics_end[52] + 500 #outlier to reflect "near the end"
decomp_mid <- plastics_mid %>%
decompose(type = "multiplicative")
p <- autoplot(plastics, series = "Data") +
autolayer(trendcycle(decomp_plastics), series = "Trend") +
autolayer(seasadj(decomp_plastics), series = "Seasonally Adjusted") +
ggtitle("Plastics Seasonally Adjusted - Original") +
theme(plot.title = element_text(size = 14))
p1 <- autoplot(plastics_mid, series = "Data") +
autolayer(trendcycle(decomp_mid), series = "Trend") +
autolayer(seasadj(decomp_mid), series = "Seasonally Adjusted") +
ggtitle("Plastics Seasonally Adjusted - Mid Observation")+
theme(plot.title = element_text(size = 14))
decomp_end <- plastics_end %>%
decompose(type = "multiplicative")
p2 <- autoplot(plastics_end, series = "Data") +
autolayer(trendcycle(decomp_end), series = "Trend") +
autolayer(seasadj(decomp_end), series = "Seasonally Adjusted") +
ggtitle("Plastics Seasonally Adjusted - Near the End Observation")+
theme(plot.title = element_text(size = 14))
grid.arrange(p, p1,p2)
head(plastics)
str(plastics)
#libraries
library(readxl)
library(tidyverse)
library(tidyverse)
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("cli")
install.packages("cli")
install.packages("cli")
#libraries
library(readxl)
library(tidyverse)
library(cli)
#libraries
library(readxl)
library(tidyverse)
#libraries
library(readxl)
library(tidyverse)
#libraries
library(readxl)
library(tidyverse)
#libraries
library(readxl)
library(tidyverse)
df <- read_excel("data.xls")
head(df)
dim(df)
# Factoring category to get a count of the elements within dataset
df$category <- as.factor(df$category)
summary(df)
paste0(sum(is.na(df))," values missing from original set")
# Plots of missing values
aggr_plot <- VIM::aggr(df, col = c("navyblue", "orange"),
numbers = T, sortVars = T,
labels = names(df),
cex.axis = 0.7, gap = 3,
ylab = c("Frequency of Missing Data", "Pattern"))
# Shadow Matrix: correlation of missing values from the dataset
x <- as.data.frame(abs(is.na(df)))
y <- x[which(sapply(x, sd) >0)] # Extracts which variables are missing/NA from the dataset
cor(y) # Tendency of NA when correlated among variables
preProcess_NAdata_model <- preProcess(as.data.frame(df), method ="medianImpute")
summary(df)
# Converting Var02 to Datetime
df$SeriesInd <- as.integer(df$SeriesInd)
df$SeriesInd <- as.POSIXct(df$SeriesInd, origin = "1970-01-01")
# Renaming SeriesInd to Date to clarify purpose
df <- df %>% rename("Datetime" = SeriesInd)
# Converting Var02 to Datetime
df$SeriesInd <- as.integer(df$SeriesInd)
df$SeriesInd <- as.POSIXct(df$SeriesInd, origin = "1970-01-01")
# Renaming SeriesInd to Date to clarify purpose
df <- df %>% rename("Datetime" = SeriesInd)
#libraries
library(readxl)
library(tidyverse)
remove.packages("cli")
install.packages("cli")
install.packages("cli")
#libraries
library(readxl)
library(tidyverse)
install.packages("dplyr")
#libraries
library(readxl)
library(tidyverse)
devtools::install_github("dplyr")
remove.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
#libraries
library(readxl)
library(tidyverse)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
#libraries
library(readxl)
library(tidyverse)
remove.packages("tidyverse")
remove.packages("rlang")
#libraries
library(readxl)
library(tidyverse)
remove.packages("vctrs")
#libraries
library(readxl)
library(tidyverse)
install.packages("vctrs")
#libraries
library(readxl)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(fpp2)
library(caret)
remove.packages("caret")
remove.packages("glue")
#libraries
library(readxl)
library(tidyverse)
install.packages("glue")
#libraries
library(readxl)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(fpp2)
library(caret)
remove.packages("tibble")
install.packages("tibble")
#libraries
library(readxl)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(fpp2)
library(caret)
library(RANN)
library(VIM)
#libraries
library(readxl)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(fpp2)
library(caret)
library(RANN)
library(VIM)
df <- read_excel("data.xls")
head(df)
dim(df)
# Factoring category to get a count of the elements within dataset
df$category <- as.factor(df$category)
summary(df)
paste0(sum(is.na(df))," values missing from original set")
# Plots of missing values
aggr_plot <- VIM::aggr(df, col = c("navyblue", "orange"),
numbers = T, sortVars = T,
labels = names(df),
cex.axis = 0.7, gap = 3,
ylab = c("Frequency of Missing Data", "Pattern"))
# Shadow Matrix: correlation of missing values from the dataset
x <- as.data.frame(abs(is.na(df)))
y <- x[which(sapply(x, sd) >0)] # Extracts which variables are missing/NA from the dataset
cor(y) # Tendency of NA when correlated among variables
preProcess_NAdata_model <- preProcess(as.data.frame(df), method ="medianImpute")
df <- predict(preProcess_NAdata_model, newdata = df)
paste0(sum(is.na(df))," values missing after imputation")
summary(df)
# Converting Var02 to Datetime
df$SeriesInd <- as.integer(df$SeriesInd)
df$SeriesInd <- as.POSIXct(df$SeriesInd, origin = "1970-01-01")
# Renaming SeriesInd to Date to clarify purpose
df <- df %>% rename("Datetime" = SeriesInd)
summary(df)
# For forecasting later on
s01 <- df %>% filter(category == "S01")
s02 <- df %>% filter(category == "S02")
s03 <- df %>% filter(category == "S03")
s04 <- df %>% filter(category == "S04")
s05 <- df %>% filter(category == "S05")
s06 <- df %>% filter(category == "S06")
p1 <- ggplot(df, aes(category, Var01)) +
geom_boxplot()
p2 <- ggplot(df, aes(category, Var02)) +
geom_boxplot()
p3 <- ggplot(df, aes(category, Var03)) +
geom_boxplot()
p4 <- ggplot(df, aes(category, Var05)) +
geom_boxplot()
p5 <- ggplot(df, aes(category, Var07)) +
geom_boxplot()
p1+p2+p3+p4+p5+
plot_layout(ncol = 2)
p1 <- ggplot(df, aes(Var01, color=category)) +
geom_density()
p2 <- ggplot(df, aes(Var02, color=category)) +
geom_density()
p3 <- ggplot(df, aes(Var03, color=category)) +
geom_density()
p4 <- ggplot(df, aes(Var05, color=category)) +
geom_density()
p5 <- ggplot(df, aes(Var07, color=category)) +
geom_density()
p1+p2+p3+p4+p5+
plot_layout(ncol = 2)
library(moments)
skewness(df$Var01)
skewness(df$Var02)
skewness(df$Var03)
skewness(df$Var05)
skewness(df$Var07)
log_var01 <- log10(df$Var01)
sqrt_var01 <- sqrt(df$Var01)
cube_var01 <- df$Var01^(1/3)
hist(df$Var01)
hist(log_var01)
hist(sqrt_var01)
hist(cube_var01)
df_transformed <- df
df_transformed$Var01 <- log10(df$Var01)
df_transformed$Var02 <- log10(df$Var02)
df_transformed$Var03 <- log10(df$Var03)
df_transformed$Var05 <- log10(df$Var05)
df_transformed$Var07 <- log10(df$Var07)
p1 <- ggplot(df_transformed, aes(Var01, color=category)) +
geom_density()
p2 <- ggplot(df_transformed, aes(Var02, color=category)) +
geom_density()
p3 <- ggplot(df_transformed, aes(Var03, color=category)) +
geom_density()
p4 <- ggplot(df_transformed, aes(Var05, color=category)) +
geom_density()
p5 <- ggplot(df_transformed, aes(Var07, color=category)) +
geom_density()
p1+p2+p3+p4+p5+
plot_layout(ncol = 2)
s01 <- df_transformed %>% dplyr::filter(category == "S01")
s02 <- df_transformed %>% dplyr::filter(category == "S02")
s03 <- df_transformed %>% dplyr::filter(category == "S03")
s04 <- df_transformed %>% dplyr::filter(category == "S04")
s05 <- df_transformed %>% dplyr::filter(category == "S05")
s06 <- df_transformed %>% dplyr::filter(category == "S06")
s01
autoplot(s01[,"Var01"])
autoplot(s01["Datetime","Var01"])
autoplot(s01)
View(df)
df_test <- read_excel("data.xls")
head(df_test)
# Converting Var02 to Datetime
df_test$SeriesInd <- as.Date(df_test$SeriesInd)
# Converting Var02 to Datetime
df_test$SeriesInd <- as.Date(df_test$SeriesInd, origin = "2011-05-06")
df_test <- df_test %>% rename("Date" = SeriesInd)
summary(df_test)
?as.Date
df_test <- read_excel("data.xls")
#head(df_test)
# Converting Var02 to Datetime
df_test$SeriesInd <- as.Date(df_test$SeriesInd, origin = "1899-12-30")
# Renaming SeriesInd to Date to clarify purpose
df_test <- df_test %>% rename("Date" = SeriesInd)
summary(df_test)
#?as.Date
preProcess_NAdata_model <- preProcess(as.data.frame(df_test), method ="medianImpute")
df_test <- predict(preProcess_NAdata_model, newdata = df_test)
paste0(sum(is.na(df_test))," values missing after imputation")
s01_2 <- df %>% filter(category == "S01")
s02_2 <- df %>% filter(category == "S02")
s03_2 <- df %>% filter(category == "S03")
s04_2 <- df %>% filter(category == "S04")
s05_2 <- df %>% filter(category == "S05")
s06_2 <- df %>% filter(category == "S06")
head(df_test)
autoplot(s01_2)
autoplot(s01_2[,"Var01"])
?ts
s01_ts <- ts(s01_2[,"Var01"], frequency = 7, start = c(2011, 1))
autoplot(s01_ts)
s01_ts
head(s01_ts)
autoplot(s01_ts)
tail(df_test)
s01_ts <- ts(s01_2[,"Var01"], frequency = 7, start = c(2011, 5), end = (2018, 5))
s01_ts <- ts(s01_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
autoplot(s01_ts)
s01_ts <- ts(s01_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
s02_ts <- ts(s02_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
s03_ts <- ts(s03_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
s04_ts <- ts(s04_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
s05_ts <- ts(s05_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
s06_ts <- ts(s06_2[,"Var01"], frequency = 7, start = c(2011, 5), end = c(2018, 5))
autoplot(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / gglagplot(s01_ts) / ggAcf(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / gglagplot(s01_ts) / ggAcf(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / gglagplot(s01_ts) / ggAcf(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / gglagplot(s01_ts) / ggAcf(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / ggAcf(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / ggAcf(s01_ts)
?as.POSIXct
df_test2 <- read_excel("data.xls")
# Converting Var02 to Datetime
df_test2$SeriesInd <- as.integer(df$SeriesInd)
df_test2 <- read_excel("data.xls")
# Converting Var02 to Datetime
df_test2$SeriesInd <- as.integer(d_test2f$SeriesInd)
df_test2 <- read_excel("data.xls")
# Converting Var02 to Datetime
df_test2$SeriesInd <- as.integer(d_test2$SeriesInd)
df_test2 <- read_excel("data.xls")
# Converting Var02 to Datetime
df_test2$SeriesInd <- as.integer(df_test2$SeriesInd)
df_test2$SeriesInd <- as.POSIXct(df_test2$SeriesInd, origin = "1960-01-01")
head(df_test2)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / ggAcf(s01_ts) / gglagplot(s01_ts)
autoplot(s01_ts) / ggseasonplot(s01_ts) / ggsubseriesplot(s01_ts) / ggAcf(s01_ts)
gglagplot(s01_ts)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
?stl
fit <- stl(s01_ts, s.window = "periodic")
fit %>% seasadj() %>% naive()%>%
autoplot()
